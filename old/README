Spark Standlone Cluster using SLURM

This directory inludes the scripts how you run a spark standalone cluster
using the job scheduler SLURM on a public cluster.

Copy the whole directory to your own account to do a test. 


The main job script file is "spark-slurm.sh"
By default, it will just use one core/worker. You may run the spark cluster 
with more cores/workers on more than one node as follows

    sbatch -N 2 -n 6  spark-slurm.sh

The jobscript file "spark-slurm.sh" basically consits of three parts: 

A. The first part is to automatically create a spark cluster used allocated 
   resources using the script "start_spark_cluster.sh". 

   The PIDs and webUI address for the spark cluster will be saved in a file named  
   like "slurm-nnnn .pid" through the life of the job. 

   You may type "cat slurm-nnnn .pid" to view it and put the webUI address 
   in a web browser started by "srun --pty firefox" to monitor the status of 
   the spark cluster. 

B. The second part is to submit your job to the spark cluster using commands like
   "spark-submit --master ${sparkmaster} ..."

C. After the job is done, stop the spark cluster using the script "stop_spark_cluster.sh"
